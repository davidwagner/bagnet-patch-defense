{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2019-6-1_threshold_model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"bjcZlN1wPdYe","colab_type":"code","colab":{}},"source":["%load_ext autoreload\n","%autoreload 2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoDjZZN4Paqn","colab_type":"code","outputId":"182909a1-62f2-4788-a660-f8078abb5947","executionInfo":{"status":"ok","timestamp":1559536935129,"user_tz":420,"elapsed":1138,"user":{"displayName":"Zhanyuan Zhang","photoUrl":"","userId":"08335047249365894118"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","os.chdir('/content/gdrive/My Drive/dl-security/') #Change the path to the directory that contains all code and data"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZI5YYXb-V_qh","colab_type":"code","colab":{}},"source":["#!pip install https://github.com/bethgelab/foolbox/archive/master.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xt5f_BN4PGvp","colab_type":"code","outputId":"d493c0dd-04e1-4699-afb1-7e001ada9e1b","executionInfo":{"status":"ok","timestamp":1559536935881,"user_tz":420,"elapsed":1820,"user":{"displayName":"Zhanyuan Zhang","photoUrl":"","userId":"08335047249365894118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from bagnets.utils import plot_heatmap, generate_heatmap_pytorch\n","from bagnets.utils import pad_image, convert2channel_last, imagenet_preprocess, extract_patches, bagnet_predict, compare_heatmap\n","from bagnets.utils import bagnet33_debug, plot_saliency, compute_saliency_map\n","from bagnets.utils import get_topk_acc, validate\n","from foolbox.utils import samples\n","import bagnets.pytorch\n","from bagnets.pytorch import Bottleneck\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","import numpy as np\n","import time\n","import os\n","img_path = \"./ILSVRC2012_img_val\"\n","root = \"./\"\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","if use_cuda:\n","    print(torch.cuda.get_device_name(0))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Oco5L6qYVwbN","colab_type":"text"},"source":["## Define clipping functions"]},{"cell_type":"code","metadata":{"id":"JTdgcWWvPRIQ","colab_type":"code","outputId":"929d8a8d-f470-4d59-98ef-b70335d367c7","executionInfo":{"status":"ok","timestamp":1559536942915,"user_tz":420,"elapsed":5706,"user":{"displayName":"Zhanyuan Zhang","photoUrl":"","userId":"08335047249365894118"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["bagnet33 = bagnets.pytorch.bagnet33(pretrained=True, avg_pool=False).to(device)\n","bagnet33.eval()\n","print()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0VUeajKuFllV","colab_type":"code","colab":{}},"source":["def clip_pm1(values, **kwargs):\n","    \"\"\"Clip values to [-1, 1]\n","    Input:\n","    - values(torch tensor): values to be clipped\n","    Output: (torch tensor) clipped values\n","    \"\"\"\n","    return torch.clamp_(values, -1., 1.)\n","\n","def clip_bias(values, b):\n","    \"\"\"Clip values to [-1, 1]\n","    Input:\n","    - values(torch tensor): values to be clipped\n","    - b (float): intersection\n","    Output: (torch tensor) clipped values\n","    \"\"\"\n","    return torch.clamp_(values + b, -1, 1)\n","\n","def clip_linear(values, a, b):\n","    \"\"\"Clip values to [-1, 1]\n","    Input:\n","    - values(torch tensor): values to be clipped\n","    - a (float): coefficient\n","    - b (float): intersection\n","    Output: (torch tensor) clipped values\n","    \"\"\"\n","    return torch.clamp_(values * a + b, -1, 1)\n","\n","def sigmoid_linear(values, a, b):\n","    \"\"\"Clip values to [-1, 1]\n","    Input:\n","    - values(torch tensor): values to be clipped\n","    - a (float): coefficient\n","    - b (float): intersection\n","    Output: (torch tensor) clipped values\n","    \"\"\"\n","    x_lin = values * a + b\n","    return torch.sigmoid(x_lin)\n","\n","def tanh_linear(values, a, b):\n","    \"\"\"Clip values to [-1, 1]\n","    Input:\n","    - values(torch tensor): values to be clipped\n","    - a (float): coefficient\n","    - b (float): intersection\n","    Output: (numpy array) clipped values\n","    \"\"\"\n","    return torch.tanh(values * a + b)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y1J7lMAIDu35","colab_type":"code","colab":{}},"source":["def clip_logits(bagnet, clip, images, **kwargs):\n","    \"\"\"Clip logits returned by patches\n","    Input:\n","    - bagnet (pytorch model): Bagnet without average pooling\n","    - clip (python function): clip function\n","    - images (pytorch tensor): \n","    \"\"\"\n","    with torch.no_grad():\n","        patch_logits = bagnet(images)\n","    return clip(patch_logits, **kwargs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UR66kT_cvfu3","colab_type":"code","colab":{}},"source":["bs = 20\n","original, labels = samples(dataset='imagenet', index=1, batchsize=bs, shape=(224, 224), data_format='channels_first')\n","images = imagenet_preprocess(original)\n","images, targets = torch.from_numpy(images).to(device), torch.from_numpy(labels).to(device)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wztabiJqv7I1","colab_type":"code","colab":{}},"source":["pm1_clip = clip_logits(bagnet33, clip_pm1, images)\n","bias_clip = clip_logits(bagnet33, clip_bias, images, b=10)\n","linear_clip = clip_logits(bagnet33, clip_linear, images, a=0.5, b=10)\n","sigmoid_clip = clip_logits(bagnet33, sigmoid_linear, images, a=0.5, b=10)\n","tanh_clip = clip_logits(bagnet33, tanh_linear, images, a=0.5, b=10)"],"execution_count":0,"outputs":[]}]}