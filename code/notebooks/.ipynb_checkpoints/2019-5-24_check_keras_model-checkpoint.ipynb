{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from bagnets.utils import plot_heatmap, generate_heatmap_pytorch\n",
    "from bagnets.utils import pad_image, convert2channel_last, imagenet_preprocess, extract_patches, bagnet_predict, compare_heatmap\n",
    "from foolbox.utils import samples\n",
    "import bagnets.keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://bitbucket.org/wielandbrendel/bag-of-feature-pretrained-models/raw/d413271344758455ac086992beb579e256447839/bagnet32.h5\n",
      "73973760/73972576 [==============================] - 4s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/models.py:282: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model\n",
    "bagnet33 = bagnets.keras.bagnet33()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             (None, 3, 224, 224)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv10.275406533888118 (Conv2D) (None, 64, 224, 224) 192         input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv20.7357471192702366 (Conv2D (None, 64, 222, 222) 36864       conv10.275406533888118[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bn10.3729843759042565 (BatchNor (None, 64, 222, 222) 256         conv20.7357471192702366[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "relu0.6721735564332428 (Activat (None, 64, 222, 222) 0           bn10.3729843759042565[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.conv10.823685875312503 (None, 64, 222, 222) 4096        relu0.6721735564332428[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.bn10.8631667425387667  (None, 64, 222, 222) 256         layer1.0.conv10.8236858753125031[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.relu0.1940005575463200 (None, 64, 222, 222) 0           layer1.0.bn10.8631667425387667[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.conv20.210127637554028 (None, 64, 110, 110) 36864       layer1.0.relu0.19400055754632006[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.bn20.7923064512724395  (None, 64, 110, 110) 256         layer1.0.conv20.2101276375540284[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.downsample.00.15395349 (None, 256, 111, 111 16384       relu0.6721735564332428[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.relu0.6377587588222584 (None, 64, 110, 110) 0           layer1.0.bn20.7923064512724395[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.downsample.10.07479916 (None, 256, 111, 111 1024        layer1.0.downsample.00.1539534976\n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.conv30.247427199075111 (None, 256, 110, 110 16384       layer1.0.relu0.6377587588222584[0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 256, 110, 111 0           layer1.0.downsample.10.0747991629\n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.bn30.451760214877312 ( (None, 256, 110, 110 1024        layer1.0.conv30.24742719907511168\n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 256, 110, 110 0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1.00.1277138891505235 (Add (None, 256, 110, 110 0           layer1.0.bn30.451760214877312[0][\n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer1.0.relu0.640493572306185  (None, 256, 110, 110 0           layer1.00.1277138891505235[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.conv10.945294808490036 (None, 64, 110, 110) 16384       layer1.0.relu0.640493572306185[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.bn10.8884586571903706  (None, 64, 110, 110) 256         layer1.1.conv10.9452948084900369[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.relu0.2167098381753990 (None, 64, 110, 110) 0           layer1.1.bn10.8884586571903706[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.conv20.857022516450007 (None, 64, 110, 110) 4096        layer1.1.relu0.21670983817539902[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.bn20.16001397631163172 (None, 64, 110, 110) 256         layer1.1.conv20.8570225164500075[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.relu0.736052165115344  (None, 64, 110, 110) 0           layer1.1.bn20.16001397631163172[0\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.conv30.253803486608240 (None, 256, 110, 110 16384       layer1.1.relu0.736052165115344[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.bn30.05809350422652171 (None, 256, 110, 110 1024        layer1.1.conv30.2538034866082405[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.10.046717307045945566 (A (None, 256, 110, 110 0           layer1.1.bn30.05809350422652171[0\n",
      "                                                                 layer1.0.relu0.640493572306185[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer1.1.relu0.7654806866188296 (None, 256, 110, 110 0           layer1.10.046717307045945566[0][0\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.conv10.457893533717217 (None, 64, 110, 110) 16384       layer1.1.relu0.7654806866188296[0\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.bn10.16568045534364606 (None, 64, 110, 110) 256         layer1.2.conv10.4578935337172175[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.relu0.2348749237120262 (None, 64, 110, 110) 0           layer1.2.bn10.16568045534364606[0\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.conv20.207598330392613 (None, 64, 110, 110) 4096        layer1.2.relu0.23487492371202623[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.bn20.9615402829940835  (None, 64, 110, 110) 256         layer1.2.conv20.20759833039261355\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.relu0.4010961586728366 (None, 64, 110, 110) 0           layer1.2.bn20.9615402829940835[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.conv30.374931909512518 (None, 256, 110, 110 16384       layer1.2.relu0.40109615867283666[\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.bn30.8141369058188784  (None, 256, 110, 110 1024        layer1.2.conv30.374931909512518[0\n",
      "__________________________________________________________________________________________________\n",
      "layer1.20.18764041966420875 (Ad (None, 256, 110, 110 0           layer1.2.bn30.8141369058188784[0]\n",
      "                                                                 layer1.1.relu0.7654806866188296[0\n",
      "__________________________________________________________________________________________________\n",
      "layer1.2.relu0.3527008644329309 (None, 256, 110, 110 0           layer1.20.18764041966420875[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.conv10.406767157155671 (None, 128, 110, 110 32768       layer1.2.relu0.3527008644329309[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.bn10.02223971600760632 (None, 128, 110, 110 512         layer2.0.conv10.4067671571556717[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.relu0.7906427765491182 (None, 128, 110, 110 0           layer2.0.bn10.022239716007606325[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.conv20.767492995167878 (None, 128, 54, 54)  147456      layer2.0.relu0.7906427765491182[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.bn20.03405503259598586 (None, 128, 54, 54)  512         layer2.0.conv20.7674929951678786[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.downsample.00.02885796 (None, 512, 55, 55)  131072      layer1.2.relu0.3527008644329309[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.relu0.3973738422943221 (None, 128, 54, 54)  0           layer2.0.bn20.03405503259598586[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.downsample.10.68006339 (None, 512, 55, 55)  2048        layer2.0.downsample.00.0288579638\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.conv30.145063015026763 (None, 512, 54, 54)  65536       layer2.0.relu0.39737384229432215[\n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 512, 54, 55)  0           layer2.0.downsample.10.6800633998\n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.bn30.27998510014545286 (None, 512, 54, 54)  2048        layer2.0.conv30.14506301502676344\n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 512, 54, 54)  0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer2.00.3322763322855147 (Add (None, 512, 54, 54)  0           layer2.0.bn30.27998510014545286[0\n",
      "                                                                 lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer2.0.relu0.5219831808591479 (None, 512, 54, 54)  0           layer2.00.3322763322855147[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.conv10.182112090919870 (None, 128, 54, 54)  65536       layer2.0.relu0.5219831808591479[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.bn10.6279149613598355  (None, 128, 54, 54)  512         layer2.1.conv10.1821120909198708[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.relu0.7665279520842521 (None, 128, 54, 54)  0           layer2.1.bn10.6279149613598355[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.conv20.020816174515316 (None, 128, 54, 54)  16384       layer2.1.relu0.7665279520842521[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.bn20.8031599283576147  (None, 128, 54, 54)  512         layer2.1.conv20.02081617451531625\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.relu0.2461557475456897 (None, 128, 54, 54)  0           layer2.1.bn20.8031599283576147[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.conv30.261744804593493 (None, 512, 54, 54)  65536       layer2.1.relu0.2461557475456897[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.bn30.9844743806846064  (None, 512, 54, 54)  2048        layer2.1.conv30.26174480459349325\n",
      "__________________________________________________________________________________________________\n",
      "layer2.10.1754367912586159 (Add (None, 512, 54, 54)  0           layer2.1.bn30.9844743806846064[0]\n",
      "                                                                 layer2.0.relu0.5219831808591479[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.1.relu0.813872722697795  (None, 512, 54, 54)  0           layer2.10.1754367912586159[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.conv10.237552455303902 (None, 128, 54, 54)  65536       layer2.1.relu0.813872722697795[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.bn10.6619410360219108  (None, 128, 54, 54)  512         layer2.2.conv10.23755245530390245\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.relu0.6896978108307297 (None, 128, 54, 54)  0           layer2.2.bn10.6619410360219108[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.conv20.634708679616258 (None, 128, 54, 54)  16384       layer2.2.relu0.6896978108307297[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.bn20.5358002785266355  (None, 128, 54, 54)  512         layer2.2.conv20.6347086796162584[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.relu0.7312673200145212 (None, 128, 54, 54)  0           layer2.2.bn20.5358002785266355[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.conv30.134086593478389 (None, 512, 54, 54)  65536       layer2.2.relu0.7312673200145212[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.bn30.43888183424118055 (None, 512, 54, 54)  2048        layer2.2.conv30.13408659347838947\n",
      "__________________________________________________________________________________________________\n",
      "layer2.20.9296691438673341 (Add (None, 512, 54, 54)  0           layer2.2.bn30.43888183424118055[0\n",
      "                                                                 layer2.1.relu0.813872722697795[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.2.relu0.5124302194929866 (None, 512, 54, 54)  0           layer2.20.9296691438673341[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.conv10.978526424574205 (None, 128, 54, 54)  65536       layer2.2.relu0.5124302194929866[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.bn10.4195643633972911  (None, 128, 54, 54)  512         layer2.3.conv10.9785264245742052[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.relu0.1205777440773582 (None, 128, 54, 54)  0           layer2.3.bn10.4195643633972911[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.conv20.276508802848083 (None, 128, 54, 54)  16384       layer2.3.relu0.12057774407735822[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.bn20.1679525518203392  (None, 128, 54, 54)  512         layer2.3.conv20.27650880284808355\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.relu0.3612593628260443 (None, 128, 54, 54)  0           layer2.3.bn20.1679525518203392[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.conv30.688981485121233 (None, 512, 54, 54)  65536       layer2.3.relu0.3612593628260443[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.bn30.2639918989612974  (None, 512, 54, 54)  2048        layer2.3.conv30.6889814851212338[\n",
      "__________________________________________________________________________________________________\n",
      "layer2.30.8255710970349265 (Add (None, 512, 54, 54)  0           layer2.3.bn30.2639918989612974[0]\n",
      "                                                                 layer2.2.relu0.5124302194929866[0\n",
      "__________________________________________________________________________________________________\n",
      "layer2.3.relu0.7483943910513773 (None, 512, 54, 54)  0           layer2.30.8255710970349265[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.conv10.132784157988177 (None, 256, 54, 54)  131072      layer2.3.relu0.7483943910513773[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.bn10.4477872593545358  (None, 256, 54, 54)  1024        layer3.0.conv10.13278415798817722\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.relu0.2888579014646674 (None, 256, 54, 54)  0           layer3.0.bn10.4477872593545358[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.conv20.847349382972011 (None, 256, 26, 26)  589824      layer3.0.relu0.2888579014646674[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.bn20.2739023000886698  (None, 256, 26, 26)  1024        layer3.0.conv20.8473493829720112[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.downsample.00.86093346 (None, 1024, 27, 27) 524288      layer2.3.relu0.7483943910513773[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.relu0.8050124733587095 (None, 256, 26, 26)  0           layer3.0.bn20.2739023000886698[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.downsample.10.71199630 (None, 1024, 27, 27) 4096        layer3.0.downsample.00.8609334654\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.conv30.171843455198228 (None, 1024, 26, 26) 262144      layer3.0.relu0.8050124733587095[0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1024, 26, 27) 0           layer3.0.downsample.10.7119963095\n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.bn30.9827864211198187  (None, 1024, 26, 26) 4096        layer3.0.conv30.1718434551982283[\n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1024, 26, 26) 0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer3.00.7961532906419279 (Add (None, 1024, 26, 26) 0           layer3.0.bn30.9827864211198187[0]\n",
      "                                                                 lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer3.0.relu0.6885723782729674 (None, 1024, 26, 26) 0           layer3.00.7961532906419279[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.conv10.931564562644279 (None, 256, 26, 26)  262144      layer3.0.relu0.6885723782729674[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.bn10.9397255420506039  (None, 256, 26, 26)  1024        layer3.1.conv10.9315645626442796[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.relu0.4732099409639940 (None, 256, 26, 26)  0           layer3.1.bn10.9397255420506039[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.conv20.922965314055228 (None, 256, 26, 26)  65536       layer3.1.relu0.47320994096399405[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.bn20.2941105104482943  (None, 256, 26, 26)  1024        layer3.1.conv20.9229653140552289[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.relu0.9669043155051322 (None, 256, 26, 26)  0           layer3.1.bn20.2941105104482943[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.conv30.068062099051454 (None, 1024, 26, 26) 262144      layer3.1.relu0.9669043155051322[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.bn30.30767660280064946 (None, 1024, 26, 26) 4096        layer3.1.conv30.06806209905145488\n",
      "__________________________________________________________________________________________________\n",
      "layer3.10.4285071230560019 (Add (None, 1024, 26, 26) 0           layer3.1.bn30.30767660280064946[0\n",
      "                                                                 layer3.0.relu0.6885723782729674[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.1.relu0.5153625088107237 (None, 1024, 26, 26) 0           layer3.10.4285071230560019[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.conv10.824324553159970 (None, 256, 26, 26)  262144      layer3.1.relu0.5153625088107237[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.bn10.7371335458459356  (None, 256, 26, 26)  1024        layer3.2.conv10.8243245531599708[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.relu0.2527920678728736 (None, 256, 26, 26)  0           layer3.2.bn10.7371335458459356[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.conv20.819920365481428 (None, 256, 26, 26)  65536       layer3.2.relu0.25279206787287367[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.bn20.2140347708303837  (None, 256, 26, 26)  1024        layer3.2.conv20.8199203654814282[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.relu0.5393027346780269 (None, 256, 26, 26)  0           layer3.2.bn20.2140347708303837[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.conv30.129163602919844 (None, 1024, 26, 26) 262144      layer3.2.relu0.5393027346780269[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.bn30.2830058777207737  (None, 1024, 26, 26) 4096        layer3.2.conv30.12916360291984497\n",
      "__________________________________________________________________________________________________\n",
      "layer3.20.05928808355527393 (Ad (None, 1024, 26, 26) 0           layer3.2.bn30.2830058777207737[0]\n",
      "                                                                 layer3.1.relu0.5153625088107237[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.2.relu0.4557981964245083 (None, 1024, 26, 26) 0           layer3.20.05928808355527393[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.conv10.057336130910865 (None, 256, 26, 26)  262144      layer3.2.relu0.45579819642450836[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.bn10.655858653699254 ( (None, 256, 26, 26)  1024        layer3.3.conv10.05733613091086598\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.relu0.7277962942455621 (None, 256, 26, 26)  0           layer3.3.bn10.655858653699254[0][\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.conv20.285418875755445 (None, 256, 26, 26)  65536       layer3.3.relu0.7277962942455621[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.bn20.8384025087045307  (None, 256, 26, 26)  1024        layer3.3.conv20.2854188757554451[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.relu0.1805379542095146 (None, 256, 26, 26)  0           layer3.3.bn20.8384025087045307[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.conv30.641938490320972 (None, 1024, 26, 26) 262144      layer3.3.relu0.18053795420951468[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.bn30.09267875280496585 (None, 1024, 26, 26) 4096        layer3.3.conv30.6419384903209728[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.30.35531604886574963 (Ad (None, 1024, 26, 26) 0           layer3.3.bn30.09267875280496585[0\n",
      "                                                                 layer3.2.relu0.45579819642450836[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.3.relu0.0335269998181125 (None, 1024, 26, 26) 0           layer3.30.35531604886574963[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.conv10.429441319139541 (None, 256, 26, 26)  262144      layer3.3.relu0.03352699981811258[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.bn10.29253324026951544 (None, 256, 26, 26)  1024        layer3.4.conv10.42944131913954164\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.relu0.0797394129720888 (None, 256, 26, 26)  0           layer3.4.bn10.29253324026951544[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.conv20.451384026732458 (None, 256, 26, 26)  65536       layer3.4.relu0.07973941297208886[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.bn20.8374350124097121  (None, 256, 26, 26)  1024        layer3.4.conv20.45138402673245837\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.relu0.3172285440219711 (None, 256, 26, 26)  0           layer3.4.bn20.8374350124097121[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.conv30.606478687594488 (None, 1024, 26, 26) 262144      layer3.4.relu0.3172285440219711[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.bn30.19518322916737774 (None, 1024, 26, 26) 4096        layer3.4.conv30.6064786875944883[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.40.8233185042641396 (Add (None, 1024, 26, 26) 0           layer3.4.bn30.19518322916737774[0\n",
      "                                                                 layer3.3.relu0.03352699981811258[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.4.relu0.2867376539740150 (None, 1024, 26, 26) 0           layer3.40.8233185042641396[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.conv10.567077367267741 (None, 256, 26, 26)  262144      layer3.4.relu0.28673765397401507[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.bn10.3193826485654817  (None, 256, 26, 26)  1024        layer3.5.conv10.5670773672677419[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.relu0.9390584832601533 (None, 256, 26, 26)  0           layer3.5.bn10.3193826485654817[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.conv20.922242913251943 (None, 256, 26, 26)  65536       layer3.5.relu0.9390584832601533[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.bn20.7502404917444881  (None, 256, 26, 26)  1024        layer3.5.conv20.9222429132519439[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.relu0.1233946221802188 (None, 256, 26, 26)  0           layer3.5.bn20.7502404917444881[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.conv30.031621735651846 (None, 1024, 26, 26) 262144      layer3.5.relu0.1233946221802188[0\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.bn30.6921912154976353  (None, 1024, 26, 26) 4096        layer3.5.conv30.03162173565184623\n",
      "__________________________________________________________________________________________________\n",
      "layer3.50.5543181036665379 (Add (None, 1024, 26, 26) 0           layer3.5.bn30.6921912154976353[0]\n",
      "                                                                 layer3.4.relu0.28673765397401507[\n",
      "__________________________________________________________________________________________________\n",
      "layer3.5.relu0.7573619251850406 (None, 1024, 26, 26) 0           layer3.50.5543181036665379[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.conv10.877306629127791 (None, 512, 26, 26)  524288      layer3.5.relu0.7573619251850406[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.bn10.7250241283707791  (None, 512, 26, 26)  2048        layer4.0.conv10.8773066291277912[\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.relu0.9222248018538503 (None, 512, 26, 26)  0           layer4.0.bn10.7250241283707791[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.conv20.326382685048727 (None, 512, 24, 24)  2359296     layer4.0.relu0.9222248018538503[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.bn20.3747336920601011  (None, 512, 24, 24)  2048        layer4.0.conv20.32638268504872703\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.downsample.00.34139534 (None, 2048, 26, 26) 2097152     layer3.5.relu0.7573619251850406[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.relu0.2444962386878939 (None, 512, 24, 24)  0           layer4.0.bn20.3747336920601011[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.downsample.10.07519204 (None, 2048, 26, 26) 8192        layer4.0.downsample.00.3413953476\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.conv30.049405786358523 (None, 2048, 24, 24) 1048576     layer4.0.relu0.24449623868789394[\n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 2048, 24, 26) 0           layer4.0.downsample.10.0751920462\n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.bn30.6731491486075161  (None, 2048, 24, 24) 8192        layer4.0.conv30.04940578635852333\n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 2048, 24, 24) 0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer4.00.8043324392939779 (Add (None, 2048, 24, 24) 0           layer4.0.bn30.6731491486075161[0]\n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer4.0.relu0.1145631448266489 (None, 2048, 24, 24) 0           layer4.00.8043324392939779[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.conv10.773022032012013 (None, 512, 24, 24)  1048576     layer4.0.relu0.11456314482664898[\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.bn10.8671428809906799  (None, 512, 24, 24)  2048        layer4.1.conv10.7730220320120137[\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.relu0.5859616778063251 (None, 512, 24, 24)  0           layer4.1.bn10.8671428809906799[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.conv20.396711674569394 (None, 512, 24, 24)  262144      layer4.1.relu0.5859616778063251[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.bn20.5381162071385078  (None, 512, 24, 24)  2048        layer4.1.conv20.3967116745693944[\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.relu0.0038447293247608 (None, 512, 24, 24)  0           layer4.1.bn20.5381162071385078[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.conv30.374138968101478 (None, 2048, 24, 24) 1048576     layer4.1.relu0.003844729324760876\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.bn30.02914320797351133 (None, 2048, 24, 24) 8192        layer4.1.conv30.37413896810147873\n",
      "__________________________________________________________________________________________________\n",
      "layer4.10.6788411929387348 (Add (None, 2048, 24, 24) 0           layer4.1.bn30.02914320797351133[0\n",
      "                                                                 layer4.0.relu0.11456314482664898[\n",
      "__________________________________________________________________________________________________\n",
      "layer4.1.relu0.6123723483078299 (None, 2048, 24, 24) 0           layer4.10.6788411929387348[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.conv10.063597823447683 (None, 512, 24, 24)  1048576     layer4.1.relu0.6123723483078299[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.bn10.11546706404258533 (None, 512, 24, 24)  2048        layer4.2.conv10.06359782344768317\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.relu0.6860676059294245 (None, 512, 24, 24)  0           layer4.2.bn10.11546706404258533[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.conv20.313991484025522 (None, 512, 24, 24)  262144      layer4.2.relu0.6860676059294245[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.bn20.6791758524991747  (None, 512, 24, 24)  2048        layer4.2.conv20.31399148402552224\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.relu0.7981566374607704 (None, 512, 24, 24)  0           layer4.2.bn20.6791758524991747[0]\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.conv30.231616775730676 (None, 2048, 24, 24) 1048576     layer4.2.relu0.7981566374607704[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.bn30.6565787190430799  (None, 2048, 24, 24) 8192        layer4.2.conv30.23161677573067607\n",
      "__________________________________________________________________________________________________\n",
      "layer4.20.5307737967069559 (Add (None, 2048, 24, 24) 0           layer4.2.bn30.6565787190430799[0]\n",
      "                                                                 layer4.1.relu0.6123723483078299[0\n",
      "__________________________________________________________________________________________________\n",
      "layer4.2.relu0.2300460389800050 (None, 2048, 24, 24) 0           layer4.20.5307737967069559[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "0.3241514644992525 (AveragePool (None, 2048, 1, 1)   0           layer4.2.relu0.23004603898000509[\n",
      "__________________________________________________________________________________________________\n",
      "0.6831689243077527 (Reshape)    (None, 2048)         0           0.3241514644992525[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "fc0.3520974258999885 (Dense)    (None, 1000)         2049000     0.6831689243077527[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 18,363,304\n",
      "Trainable params: 18,310,184\n",
      "Non-trainable params: 53,120\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bagnet33.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original, label = samples(dataset='imagenet', index=1, batchsize=1, shape=(224, 224), data_format='channels_first')\n",
    "\n",
    "# preprocess sample image\n",
    "sample = original / 255.\n",
    "sample -= np.array([0.485, 0.456, 0.406])[:, None, None]\n",
    "sample /= np.array([0.229, 0.224, 0.225])[:, None, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_heatmap_keras(model, image, target, patchsize):\n",
    "    \"\"\"\n",
    "    Generates high-resolution heatmap for a BagNet by decomposing the\n",
    "    image into all possible patches and by computing the logits for\n",
    "    each patch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : Pytorch Model\n",
    "        This should be one of the BagNets.\n",
    "    image : Numpy array of shape [1, 3, X, X]\n",
    "        The image for which we want to compute the heatmap.\n",
    "    target : int\n",
    "        Class for which the heatmap is computed.\n",
    "    patchsize : int\n",
    "        The size of the receptive field of the given BagNet.\n",
    "    \n",
    "    \"\"\"\n",
    "    _, c, x, y = image.shape\n",
    "    padded_image = np.zeros((c, x + patchsize - 1, y + patchsize - 1))\n",
    "    padded_image[:, (patchsize-1)//2:(patchsize-1)//2 + x, (patchsize-1)//2:(patchsize-1)//2 + y] = image[0]\n",
    "    image = padded_image[None].astype(np.float32)\n",
    "    \n",
    "    # extract patches\n",
    "    patches = np.transpose(image, (0, 2, 3, 1))\n",
    "    patches = patches.unfold(1, patchsize, 1).unfold(2, patchsize, 1)\n",
    "    num_rows = patches.shape[1]\n",
    "    num_cols = patches.shape[2]\n",
    "    patches = patches.reshape((-1, 3, patchsize, patchsize))\n",
    "    \n",
    "    # compute logits for each patch\n",
    "    logits_list = []\n",
    "    for batch_patches in torch.split(patches, 1000):\n",
    "        logits = model(batch_patches)\n",
    "        logits = logits[:, target][:, 0]\n",
    "        logits_list.append(logits.data.cpu().numpy().copy())\n",
    "    \n",
    "    logits = np.hstack(logits_list)\n",
    "    return logits.reshape((224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'unfold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4c842537aeba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mheatmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_heatmap_keras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbagnet33\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-b1b6ada1dc98>\u001b[0m in \u001b[0;36mgenerate_heatmap_keras\u001b[0;34m(model, image, target, patchsize)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# extract patches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mnum_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnum_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'unfold'"
     ]
    }
   ],
   "source": [
    "# generate heatmap\n",
    "heatmap = generate_heatmap_keras(bagnet33, sample, label, 33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
